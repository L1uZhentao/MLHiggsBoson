{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import pandas as pd\n",
    "from implementations import *\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from preprocess import *\n",
    "from knn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_full_idx 11\n",
      "2\n",
      "0 50\n",
      "[[ 132.049   79.589   23.916 ... -999.    -999.       0.   ]\n",
      " [ 106.398   67.49    87.949 ... -999.    -999.      47.575]\n",
      " [ 117.794   56.226   96.358 ... -999.    -999.       0.   ]\n",
      " ...\n",
      " [ 107.052   32.062   68.288 ...   -3.433    2.785  113.525]\n",
      " [  95.534   41.53    58.648 ... -999.    -999.     148.942]\n",
      " [ 132.049   58.57   111.162 ... -999.    -999.      30.208]]\n",
      "size_full_idx 15\n",
      "3\n",
      "0 50\n",
      "[[138.47   51.655  97.827 ...   1.24   -2.475 113.497]\n",
      " [160.937  68.768 103.235 ...  -2.385   1.876  46.226]\n",
      " [120.506 162.172 125.953 ...  -2.385   1.876  44.251]\n",
      " ...\n",
      " [130.079  53.335  97.435 ...   1.773  -2.079   0.   ]\n",
      " [167.534  41.277 123.308 ...  -1.285  -0.995   0.   ]\n",
      " [ 95.407  21.584  67.766 ...   1.24   -2.475   0.   ]]\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train, ids = load_csv_data(\"data/train.csv\")\n",
    "_, X_test, ids_test = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "preproc = Preprocessor()\n",
    "preproc.fit(X_train)\n",
    "norm_x_train = preproc.standardize(X_train)\n",
    "norm_x_test = preproc.standardize(X_test)\n",
    "X_test = knn_random_fill(X_test, norm_x_test, X_train, norm_x_train)\n",
    "X_train = knn_random_fill(X_train, norm_x_train, X_train, norm_x_train)\n",
    "\n",
    "\n",
    "ids = ids[0:1000]\n",
    "# replace empty value -999 by nan.\n",
    "X_train[X_train == -999] = np.nan\n",
    "X_test[X_test == -999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/train.csv\")\n",
    "column_names = f.readline().strip().split(\",\")[2:]\n",
    "f.close()\n",
    "# print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_num_subset(X, y):\n",
    "    \"\"\"\n",
    "    Based on jet_num, we split the dataset into 3 subsets, with jet_num = 0, 1, and 2 or more.\n",
    "    \"\"\"\n",
    "    zero = X[:, 22] == 0\n",
    "    one = X[:, 22] == 1\n",
    "    others = X[:, 22] >= 2\n",
    "\n",
    "    X_others, y_others = X[others], y[others]\n",
    "    X_zero, y_zero = X[zero], y[zero]\n",
    "    X_one, y_one = X[one], y[one]\n",
    "\n",
    "    return X_zero, y_zero, X_one, y_one, X_others, y_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test and train datasets by jet numbs.\n",
    "(\n",
    "    X_train_zero,\n",
    "    y_train_zero,\n",
    "    X_train_one,\n",
    "    y_train_one,\n",
    "    X_train_many,\n",
    "    y_train_many,\n",
    ") = jet_num_subset(X_train, y_train)\n",
    "(\n",
    "    X_test_zero,\n",
    "    ids_test_zero,\n",
    "    X_test_one,\n",
    "    ids_test_one,\n",
    "    X_test_many,\n",
    "    ids_test_many,\n",
    ") = jet_num_subset(X_test, ids_test)\n",
    "\n",
    "X_train_full = X_train.copy()\n",
    "X_test_full = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined accuracy:  0.8149636667386367\n",
      "Combined alternative F1:  0.8629820730608789\n",
      "Combined F1:  0.7151299847891536\n"
     ]
    }
   ],
   "source": [
    "def combine_f1_scores(values_1, count_1, values_2, count_2, values_3, count_3):\n",
    "    \"\"\"\n",
    "    Merges together F1 score and accuracy on subsets of data\n",
    "    Arguments: values_i: Triple of the form 1-accuracy,F_1_neg_score, F_1_pos_score as returned by the compute loss function\n",
    "               count_i: How many elements are in that set\n",
    "    \"\"\"\n",
    "    TP_list = []\n",
    "    TN_list = []\n",
    "    FNR_FPR = []\n",
    "    for (i, count) in zip([values_1, values_2, values_3], [count_1, count_2, count_3]):\n",
    "        (minus_acc, F_1_pos, F_1_neg) = i\n",
    "        acc = (1 - minus_acc) * count\n",
    "        true_negs = F_1_neg * (count - acc) / (2 * (1 - F_1_neg))\n",
    "        true_pos = acc - true_negs\n",
    "        fnr_fpr = (2 * true_pos * (1 - F_1_pos)) / F_1_pos\n",
    "        TP_list.append(true_pos)\n",
    "        TN_list.append(true_negs)\n",
    "        FNR_FPR.append(fnr_fpr)\n",
    "    print(\n",
    "        \"Combined accuracy: \",\n",
    "        (sum(TP_list) + sum(TN_list)) / (count_1 + count_2 + count_3),\n",
    "    )\n",
    "    print(\n",
    "        \"Combined alternative F1: \",\n",
    "        (2 * sum(TP_list)) / (2 * sum(TP_list) + sum(FNR_FPR)),\n",
    "    )\n",
    "    print(\"Combined F1: \", (2 * sum(TN_list)) / (2 * sum(TN_list) + sum(FNR_FPR)))\n",
    "\n",
    "\n",
    "first = (0.15378071360656553, 0.900165686624866, 0.6654327708219924)\n",
    "second = (0.21323102714552844, 0.8393334305008988, 0.6830857690464782)\n",
    "third = (0.19794610241918809, 0.8222772277227722, 0.7766371130813501)\n",
    "\n",
    "combine_f1_scores(first, 99913, second, 77544, third, 72543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 30)\n",
      "(11, 30)\n",
      "(15, 30)\n",
      "(50, 30)\n"
     ]
    }
   ],
   "source": [
    "# ()\n",
    "X_train_zero, X_test_zero = clip_outliers(X_train_zero, X_test_zero)\n",
    "X_train_one, X_test_one = clip_outliers(X_train_one, X_test_one)\n",
    "X_train_many, X_test_many = clip_outliers(X_train_many, X_test_many)\n",
    "X_train_full, X_test_full = clip_outliers(X_train_full, X_test_full)\n",
    "print(X_train_zero.shape)\n",
    "print(X_train_one.shape)\n",
    "print(X_train_many.shape)\n",
    "print(X_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_proportion(X):\n",
    "    return np.count_nonzero(np.isnan(X), axis=0) / len(X)\n",
    "\n",
    "\n",
    "def all_missing_indices(X):\n",
    "    return X == 1\n",
    "\n",
    "\n",
    "def no_missing_indices(X):\n",
    "    return X == 0\n",
    "\n",
    "\n",
    "def partial_missing_indices(X):\n",
    "    return (X > 0) & (X < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg_X(X_train_set, X_test_set):\n",
    "    \"\"\"\n",
    "    Performs some of our  feature engineering, replaces missing values and adds the binary encoding.\n",
    "    \"\"\"\n",
    "    # replace empty value -999 by nan.\n",
    "    X_train_set[X_train_set == -999] = np.nan\n",
    "    X_test_set[X_test_set == -999] = np.nan\n",
    "\n",
    "    # Get the missing value proportion for each column\n",
    "    X_train_set_missing_proportion = missing_value_proportion(X_train_set)\n",
    "\n",
    "    # X_train_set\n",
    "    X_partial_missing = partial_missing_indices(X_train_set_missing_proportion)\n",
    "\n",
    "    # Store new column to indicate whether the value is missing or not\n",
    "    new_col_X_train = np.where(np.isnan(X_train_set[:, X_partial_missing]), 0, 1)\n",
    "    new_col_X_test = np.where(np.isnan(X_test_set[:, X_partial_missing]), 0, 1)\n",
    "\n",
    "    # fill missing value with median\n",
    "    X_train_set_median = np.nanmedian(X_train_set[:, X_partial_missing])\n",
    "    arr = X_train_set[:, X_partial_missing]\n",
    "    arr[np.isnan(arr)] = X_train_set_median\n",
    "    X_train_set[:, X_partial_missing] = arr\n",
    "\n",
    "    arr = X_test_set[:, X_partial_missing]\n",
    "    arr[np.isnan(arr)] = X_train_set_median\n",
    "    X_test_set[:, X_partial_missing] = arr\n",
    "\n",
    "    # drop the columns with all missing values for X_train and X_test\n",
    "    X_zero_to_delete = all_missing_indices(X_train_set_missing_proportion)\n",
    "    X_train_set = np.delete(X_train_set, X_zero_to_delete, axis=1)\n",
    "    X_test_set = np.delete(X_test_set, X_zero_to_delete, axis=1)\n",
    "\n",
    "    # Add the new column\n",
    "    X_train_set = np.hstack([new_col_X_train, X_train_set])\n",
    "    X_test_set = np.hstack([new_col_X_test, X_test_set])\n",
    "    return X_train_set, X_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "X_train_zero, X_test_zero = feature_engg_X(X_train_zero, X_test_zero)\n",
    "X_train_one, X_test_one = feature_engg_X(X_train_one, X_test_one)\n",
    "X_train_many, X_test_many = feature_engg_X(X_train_many, X_test_many)\n",
    "\n",
    "X_train_full, X_test_full = feature_engg_X(X_train_full, X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss(y, prediction):\n",
    "    \"\"\"Computes 1-accuracy of prediction, and also the F1-score\"\"\"\n",
    "    # y values are either -1 or 1.\n",
    "    # So if prediction and y are both negative -> it's correct or if prediction and y both are positive -> it's correct\n",
    "    accuracy = ((y < 0.5) == (prediction < 0.5)).sum() / y.shape[0]\n",
    "    TPR = ((y < 0.5) & (prediction < 0.5)).sum()\n",
    "    FNR = ((y < 0.5) & (prediction >= 0.5)).sum()\n",
    "    FPR = ((y >= 0.5) & (prediction < 0.5)).sum()\n",
    "    TNR = ((y >= 0.5) & (prediction >= 0.5)).sum()\n",
    "    # Depending on what one labels as a \"positive\" and what as a \"negative\" a different one of the F1 scores is relevant here.\n",
    "    F_1_score = 2 * TPR / (2 * TPR + FNR + FPR)\n",
    "    alt_F_1_score = 2 * TNR / (2 * TNR + FNR + FPR)\n",
    "    return 1 - accuracy, F_1_score, alt_F_1_score\n",
    "\n",
    "\n",
    "import itertools  # In standard library so should be allowed?\n",
    "\n",
    "\n",
    "def tune_hyperparamters(\n",
    "    model, parameter_ranges, train_x, train_y, test_x, test_y, metric=compute_loss_mse\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a model and a list of parameters to that model and their ranges,\n",
    "    for each combination of parameters this model will train them on the training dataset and then evaluate them on the test set.\n",
    "    It returns the best parameters and their corresponding loss.\n",
    "    Expects the model to take inputs in the following day: y,X, and then the parameters specified in the input in the same order.\n",
    "    \"\"\"\n",
    "    best_loss = None\n",
    "    best_param = None\n",
    "    best_w = None\n",
    "    for param in itertools.product(*parameter_ranges):\n",
    "        w_vec, train_loss = model(train_y, train_x, *param)\n",
    "        validation_loss = metric(test_y, test_x @ w_vec)\n",
    "        if model in [logistic_regression, reg_logistic_regression]:\n",
    "            prediction = sigmoid(test_x @ w_vec)\n",
    "            validation_loss = metric(test_y, prediction)\n",
    "\n",
    "        if best_loss == None or validation_loss < best_loss:\n",
    "            best_loss, best_param = (validation_loss, param)\n",
    "            best_w = w_vec\n",
    "    return best_param, best_loss, best_w\n",
    "\n",
    "\n",
    "def tune_model(\n",
    "    model,\n",
    "    parameter_ranges,\n",
    "    poly_degree,\n",
    "    dimension,\n",
    "    train_x,\n",
    "    train_y,\n",
    "    test_x,\n",
    "    test_y,\n",
    "    metric=compute_loss_mse,\n",
    "):\n",
    "    \"\"\"\n",
    "    model: The model to optimize\n",
    "    parameter_ranges: The input parameters to the model and the ranges to search for those\n",
    "    poly_degree: List of degrees to use for polynomial expansion\n",
    "    dimension: Dimension to project data down to using PCA\n",
    "    train_x,train_y,test_x,test_y: Train and test data\n",
    "    metric: Metric to use to compare. E.g. compute_loss_mse. Should expect two inputs: y and prediction\n",
    "    Will perform an extensive hyperparameter search and return the ones that give the lowest value in the metric.\n",
    "    Expects the model to take inputs in the following day: y,X, and then the parameters specified in the input in the same order.\n",
    "    Return: best_param, best_loss, degree, dimension\n",
    "    The best parameters in the parameter_ranges, the loss achieved for those, the degree of the polynomial expansion for the best value and the dimension\n",
    "    \"\"\"\n",
    "    best_loss = None\n",
    "    best_param = None\n",
    "    best_degree = None\n",
    "    best_dimension = None\n",
    "    best_w = None\n",
    "    for degree in poly_degree:\n",
    "        poly_mapped_train = build_poly(train_x, degree)\n",
    "        poly_mapped_test = build_poly(test_x, degree)\n",
    "\n",
    "        preproc = Preprocessor()\n",
    "        preproc.fit(poly_mapped_train)\n",
    "        poly_mapped_train = preproc.standardize(poly_mapped_train)\n",
    "        poly_mapped_test = preproc.standardize(poly_mapped_test)\n",
    "\n",
    "        for pca_dimension in dimension:\n",
    "            if pca_dimension > poly_mapped_train.shape[1]:\n",
    "                continue\n",
    "            mapped_train, _ = preproc.PCA(poly_mapped_train, pca_dimension)\n",
    "            mapped_test, _ = preproc.PCA(poly_mapped_test, pca_dimension)\n",
    "\n",
    "            # Specifiy a constant inital w such that it is of the right size for our adjusted data\n",
    "            cur_param_range = parameter_ranges.copy()\n",
    "            for i in range(0, len(parameter_ranges)):\n",
    "                if parameter_ranges[i] == \"initial_w\":\n",
    "                    cur_param_range[i] = [np.zeros(mapped_train.shape[1])]\n",
    "            # Tune all other parameters\n",
    "            param, cur_loss, w = tune_hyperparamters(\n",
    "                model,\n",
    "                cur_param_range,\n",
    "                mapped_train,\n",
    "                train_y,\n",
    "                mapped_test,\n",
    "                test_y,\n",
    "                metric,\n",
    "            )\n",
    "            if best_loss == None or cur_loss < best_loss:\n",
    "                best_loss, best_param = (cur_loss, param)\n",
    "                best_degree, best_dimension = degree, pca_dimension\n",
    "                best_w = w\n",
    "    return best_param, best_loss, best_degree, best_dimension, best_w\n",
    "\n",
    "\n",
    "def predict(X_test, ids, w, X_train, dimension, poly_degree, logistic=False):\n",
    "    \"\"\"\n",
    "    Performs the model prediction.\n",
    "    Given test dataset, the corresponding IDs, weight vector w, train dataset, PCA target dimension, polynomial degree, and a Boolean to indicate if we should use the sigmoid function or not, this generates the predictions and returns them.\n",
    "    \"\"\"\n",
    "    poly_mapped_test = build_poly(X_test, poly_degree)\n",
    "    poly_mapped_train = build_poly(X_train, poly_degree)\n",
    "    preproc = Preprocessor()\n",
    "    preproc.fit(poly_mapped_train)\n",
    "    poly_mapped_train = preproc.standardize(poly_mapped_train)\n",
    "    poly_mapped_test = preproc.standardize(poly_mapped_test)\n",
    "    mapped_test, _ = preproc.PCA(poly_mapped_test, dimension)\n",
    "    prediction = mapped_test @ w\n",
    "    if logistic:\n",
    "        prediction = sigmoid(prediction)\n",
    "    for index in range(0, prediction.shape[0]):\n",
    "        if prediction[index] < 0.5:\n",
    "            prediction[index] = 0\n",
    "        else:\n",
    "            prediction[index] = 1\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mse_gd(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well mse_gd works with various parameters\n",
    "    \"\"\"\n",
    "    max_iters = [500]\n",
    "    gamma = [0.001, 0.005, 0.01, 0.015]\n",
    "    parameter_ranges = [\"initial_w\", max_iters, gamma]\n",
    "    poly_degree = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    dimension = [\n",
    "        1,\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        45,\n",
    "        50,\n",
    "        55,\n",
    "        60,\n",
    "        65,\n",
    "        70,\n",
    "        75,\n",
    "        80,\n",
    "        90,\n",
    "        100,\n",
    "        110,\n",
    "        120,\n",
    "        130,\n",
    "        140,\n",
    "        150,\n",
    "        160,\n",
    "        170,\n",
    "        180,\n",
    "        190,\n",
    "        200,\n",
    "        220,\n",
    "        240,\n",
    "        260,\n",
    "        280,\n",
    "        300,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        mean_squared_error_gd,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "    prediction = predict(\n",
    "        X_test, ids_test, best_w, train_x, best_dimension, best_degree, False\n",
    "    )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mse_sgd(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well mse_sgd works with various parameters\n",
    "    \"\"\"\n",
    "    max_iters = [50, 1000]\n",
    "    gamma = [0.001, 0.0025, 0.005, 0.01, 0.025, 0.1]\n",
    "    parameter_ranges = [\"initial_w\", max_iters, gamma]\n",
    "    poly_degree = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "    dimension = [\n",
    "        50,\n",
    "        75,\n",
    "        100,\n",
    "        115,\n",
    "        120,\n",
    "        125,\n",
    "        130,\n",
    "        135,\n",
    "        175,\n",
    "        200,\n",
    "        250,\n",
    "        300,\n",
    "        305,\n",
    "        310,\n",
    "        315,\n",
    "        320,\n",
    "        325,\n",
    "        330,\n",
    "        335,\n",
    "        340,\n",
    "        345,\n",
    "        350,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        mean_squared_error_sgd,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "\n",
    "    prediction = predict(\n",
    "        X_test, ids_test, best_w, train_x, best_dimension, best_degree, False\n",
    "    )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ridge(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well ridge regression works with various parameters\n",
    "    \"\"\"\n",
    "    lambda_ = np.logspace(-20, 2, 150)\n",
    "    parameter_ranges = [lambda_]\n",
    "    poly_degree = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "    dimension = [\n",
    "        50,\n",
    "        75,\n",
    "        100,\n",
    "        115,\n",
    "        120,\n",
    "        125,\n",
    "        130,\n",
    "        135,\n",
    "        175,\n",
    "        200,\n",
    "        250,\n",
    "        300,\n",
    "        305,\n",
    "        310,\n",
    "        315,\n",
    "        320,\n",
    "        325,\n",
    "        330,\n",
    "        335,\n",
    "        340,\n",
    "        345,\n",
    "        350,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        ridge_regression,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "    prediction = predict(\n",
    "        X_test, ids_test, best_w, train_x, best_dimension, best_degree, False\n",
    "    )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_log_regr(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well ridge regression works with various parameters\n",
    "    \"\"\"\n",
    "    max_iters = [500]\n",
    "    gamma = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    parameter_ranges = [\"initial_w\", max_iters, gamma]\n",
    "    poly_degree = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    dimension = [\n",
    "        1,\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        45,\n",
    "        50,\n",
    "        55,\n",
    "        60,\n",
    "        65,\n",
    "        70,\n",
    "        75,\n",
    "        80,\n",
    "        90,\n",
    "        100,\n",
    "        110,\n",
    "        120,\n",
    "        130,\n",
    "        140,\n",
    "        150,\n",
    "        160,\n",
    "        170,\n",
    "        180,\n",
    "        190,\n",
    "        200,\n",
    "        220,\n",
    "        240,\n",
    "        260,\n",
    "        280,\n",
    "        300,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        logistic_regression,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "\n",
    "    return predict(X_test, ids_test, best_w, train_x, best_dimension, best_degree, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reg_log_regr(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well ridge regression works with various parameters\n",
    "    \"\"\"\n",
    "    max_iters = [500]\n",
    "    gamma = [0.001, 0.05, 0.1, 0.15]\n",
    "    lambda_ = np.logspace(-10, 2, 25)\n",
    "    parameter_ranges = [lambda_, \"initial_w\", max_iters, gamma]\n",
    "    poly_degree = [3, 4, 5, 6, 7]\n",
    "    dimension = [\n",
    "        1,\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        45,\n",
    "        50,\n",
    "        55,\n",
    "        60,\n",
    "        65,\n",
    "        70,\n",
    "        75,\n",
    "        80,\n",
    "        90,\n",
    "        100,\n",
    "        110,\n",
    "        120,\n",
    "        130,\n",
    "        140,\n",
    "        150,\n",
    "        160,\n",
    "        170,\n",
    "        180,\n",
    "        190,\n",
    "        200,\n",
    "        220,\n",
    "        240,\n",
    "        260,\n",
    "        280,\n",
    "        300,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        reg_logistic_regression,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "    return predict(X_test, ids_test, best_w, train_x, best_dimension, best_degree, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_least_squares(train_x, train_y, test_x, test_y, X_test):\n",
    "    \"\"\"\n",
    "    Evaluates how well least squares works with various parameters\n",
    "    \"\"\"\n",
    "    parameter_ranges = []\n",
    "    poly_degree = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "    dimension = [\n",
    "        50,\n",
    "        75,\n",
    "        100,\n",
    "        115,\n",
    "        120,\n",
    "        125,\n",
    "        130,\n",
    "        135,\n",
    "        175,\n",
    "        200,\n",
    "        250,\n",
    "        300,\n",
    "        305,\n",
    "        310,\n",
    "        315,\n",
    "        320,\n",
    "        325,\n",
    "        330,\n",
    "        335,\n",
    "        340,\n",
    "        345,\n",
    "        350,\n",
    "    ]\n",
    "    best_param, best_loss, best_degree, best_dimension, best_w = tune_model(\n",
    "        least_squares,\n",
    "        parameter_ranges,\n",
    "        poly_degree,\n",
    "        dimension,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        accuracy_loss,\n",
    "    )\n",
    "    print(best_param, best_loss, best_degree, best_dimension)\n",
    "    accuracy = 1 - best_loss[0]\n",
    "    f_1_score = best_loss[2]\n",
    "    print(\n",
    "        f\"Optimum found, using degree {best_degree} and dimension {best_dimension} achieved accuracy of {accuracy} and F1 score of {f_1_score}\"\n",
    "    )\n",
    "\n",
    "    prediction = predict(\n",
    "        X_test, ids_test, best_w, train_x, best_dimension, best_degree, False\n",
    "    )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_each_jet_set(X_train, y_train, X_test, model_evaluate=evaluate_least_squares):\n",
    "    \"\"\"\n",
    "    Given a single subset of data, trains the model and generates the predictions from that.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_val, y_train, y_val = split_data(X_train, y_train, 0.8, 123)\n",
    "\n",
    "    pred = model_evaluate(X_train, y_train, X_val, y_val, X_test)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred_all_sets(\n",
    "    X_train_list,\n",
    "    y_train_list,\n",
    "    X_test_list,\n",
    "    id_list,\n",
    "    model_to_evaluate=evaluate_least_squares,\n",
    "    output_name=\"prediction.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train_list: A list of our X_train sets\n",
    "    y_train_list: A list of our output values for the train sets\n",
    "    X_test_list: A list of outputs to predict using our trained model\n",
    "    id_list: A list of the output IDs for the tests.\n",
    "    model_to_evaluate: One of the evaluate_* functions to use to evaluate the model\n",
    "    output_name: Name of output file to write\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for (X_train, y_train, X_test) in zip(X_train_list, y_train_list, X_test_list):\n",
    "        labels.append(pred_each_jet_set(X_train, y_train, X_test, model_to_evaluate))\n",
    "    label_all = np.hstack(labels)\n",
    "    ids_test = np.hstack(id_list)\n",
    "    create_csv_submission(ids_test, label_all, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 0., 0., 0.]), 500, 0.01) (0.19999999999999996, 0.8, 0.8) 8 5\n",
      "Optimum found, using degree 8 and dimension 5 achieved accuracy of 0.8 and F1 score of 0.8\n",
      "(array([0., 0., 0., 0., 0.]), 500, 0.01) (0.33333333333333337, 0.6666666666666666, 0.6666666666666666) 3 5\n",
      "Optimum found, using degree 3 and dimension 5 achieved accuracy of 0.6666666666666666 and F1 score of 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Documents\\Actual_Documents\\ETH\\Sem_3\\machine_learninig\\project1\\ml-project-1-luminous-hack\\implementations.py:199: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - grad * gamma\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_29932\\3540802968.py:11: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  F_1_score = 2 * TPR / (2 * TPR + FNR + FPR)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_29932\\3540802968.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  alt_F_1_score = 2 * TNR / (2 * TNR + FNR + FPR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.]), 500, 0.001) (0.0, 1.0, 1.0) 2 1\n",
      "Optimum found, using degree 2 and dimension 1 achieved accuracy of 1.0 and F1 score of 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_mse_gd,\n",
    "    \"mse_gd.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Documents\\Actual_Documents\\ETH\\Sem_3\\machine_learninig\\project1\\ml-project-1-luminous-hack\\implementations.py:247: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(tx, y)[0]\n"
     ]
    }
   ],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_least_squares,\n",
    "    \"lsqs.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_mse_sgd,\n",
    "    \"mse_sgd.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_ridge,\n",
    "    \"ridge.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_log_regr,\n",
    "    \"log_regr.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_reg_log_regr,\n",
    "    \"reg_log_regr.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we do it all for the combined dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_mse_gd,\n",
    "    \"combined_mse_gd.csv\",\n",
    ")\n",
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_least_squares,\n",
    "    \"combined_lsqs.csv\",\n",
    ")\n",
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_mse_sgd,\n",
    "    \"combined_mse_sgd.csv\",\n",
    ")\n",
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_ridge,\n",
    "    \"combined_ridge.csv\",\n",
    ")\n",
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_log_regr,\n",
    "    \"combined_log_regr.csv\",\n",
    ")\n",
    "pred_all_sets(\n",
    "    [X_train_zero, X_train_one, X_train_many],\n",
    "    [y_train_zero, y_train_one, y_train_many],\n",
    "    [X_test_zero, X_test_one, X_test_many],\n",
    "    [ids_test_zero, ids_test_one, ids_test_many],\n",
    "    evaluate_reg_log_regr,\n",
    "    \"combined_reg_log_regr.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37083a178839ddb6837eca99e3841ef7be6dad5dc50c6d19829e2187d61ddd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
